# Machine Learning Error Analysis Report
### Introduction to Programming in Science and Engineering Section 1
#### David Alexander and Dingyi Zhang

## Distributions of Model Accuracy
1. Every time we run the program again, we get a random new test and training set, which will lead to different precision, recall and accuracy for every iteration.
2. Accuracy (how many we got right over the total population) hovers around 97% with a standard deviation of 0.017
The accuracy of our model is almost constant every time. The accuracy is very high, but we have nothing to compare it to. So how good is it really? If the algorithm did nothing but guess that the tumor is malignant to try to game the system, how precise would it be? The frequency of malignant tumors in the data set is about 45%, so this should be our baseline. Therefore, our algorithm is more than twice as accurate. It is also more useful, for reasons we shall cover.
## Analysis of Different Error Types
In the medical field, we care about "false positives" and "false negatives". False positives are, for example, benign tumors that were identified as malignant, and false negatives are malignant tumors that were identified as benign. These are extremely dangerous, as these malignant tumors will be dismissed. We want to ensure that we catch all the malignant tumors, and that we minimize false positives. So we measure accuracy, which is the number of true positives over the total amount of positive identifications, and recall, the number of positive identifications over the total number of malignant tumors. These are both around 95%, with standard deviations around 0.08-0.07. The baseline for precision should be the precision if we just guess the label. This means that, if about 45% of the set is malignant, we would identify half of them, or about 23%, and we would identify 50% of the set as malignant. Our baseline is 23%/50%, or 46%. Our precision is more than twice that. For recall, the baseline would be 50% , as we would guess that half of the malignant tumors are positives. These two parameters can also be affected by the hyperparameter k, the number of neighbours. However, this effect is minimal, and there is only a notable increase in standard deviation (which is not a good thing). This is because only a few of the classifications will be changed by increasing k; specifically, the ones at the extremes of the malignant set.